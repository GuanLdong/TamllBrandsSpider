{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调取Chrome浏览器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "with sqlite3.connect('TmallInformation.db') as con :\n",
    "    # 读取数据\n",
    "    Items = pd.read_sql(sql = 'select * from items;',con=con,index_col='index')['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0     进口纯牛奶\n",
       "1      进口酸奶\n",
       "2    进口成人奶粉\n",
       "3    进口含乳饮料\n",
       "4    进口有机牛奶\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Items[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抓取三级类目思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们直接访问天猫的时候，我们可以在首页通过解析JSON拿到一二级分类的信息，之后我们想查看二级分类下的具体推荐品牌就需要我们使用搜索功能。\n",
    "\n",
    "[![knLZQ0.md.png](https://s2.ax1x.com/2019/01/26/knLZQ0.md.png)](https://imgchr.com/i/knLZQ0)\n",
    "\n",
    "如图所示，我们在搜索框中输入二级分类名称，单击搜索，就可以看到在搜索栏下方就是我们想要的品牌信息，但可惜这部分信息不是JSON，我们需要在单击一下更多才能看到全部的推荐品牌信息。\n",
    "\n",
    "于是我们就有了获取三级类目的程序流程：\n",
    "```\n",
    "for 三级类目 in 品牌数据集：\n",
    "    1.访问天猫超市首页\n",
    "    2.在搜索框中输入 三级类目\n",
    "    3.单击搜索\n",
    "    4.抓取推荐的品牌信息\n",
    " ```\n",
    " 我们主要使用selenium+chrome的方式登录。万幸，如果从首页通过搜索访问三级类目不需要登录，所以这部分代码实现起来比较简单，在写整个程序的时候我尝试了很多解决登录问题的方法，但很多都失败了，原因是天猫的反爬机制更新的太快了，写爬虫就像猜谜一样，你把所有方法都试一遍总能爬到数据，但对于个人来讲长进不大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wheel 0 - 2\n",
      "Th- 1 start\titems is :  index\n",
      "129    牛肉筋\n",
      "130     猪肉\n",
      "Name: text, dtype: object\n",
      "牛肉筋\n",
      "牛肉筋--完成抓取\n",
      "猪肉\n",
      "猪肉--完成抓取\n",
      "save success\n",
      "Wheel  0  OVER\n",
      "Wheel 2 - 4\n",
      "Th- 1 start\titems is :  index\n",
      "131       鸡鸭禽\n",
      "513    积木拼图系列\n",
      "Name: text, dtype: object\n",
      "鸡鸭禽\n",
      "鸡鸭禽 LOST!!!!\n",
      ".*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*\n",
      "鸡鸭禽--完成抓取\n",
      "积木拼图系列\n",
      "积木拼图系列 LOST!!!!\n",
      ".*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*\n",
      "积木拼图系列--完成抓取\n",
      "save success\n",
      "Wheel  1  OVER\n",
      "Wheel 4 - 6\n",
      "Th- 1 start\titems is :  index\n",
      "514    早教/音乐/智能玩具\n",
      "515          奶粉辅食\n",
      "Name: text, dtype: object\n",
      "早教/音乐/智能玩具\n",
      "早教/音乐/智能玩具 LOST!!!!\n",
      ".*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*.*\n",
      "早教/音乐/智能玩具--完成抓取\n",
      "奶粉辅食\n",
      "奶粉辅食--完成抓取\n",
      "save success\n",
      "Wheel  2  OVER\n",
      "Wheel 6 - 8\n",
      "Th- 1 start\titems is :  index\n",
      "516    帮宝适\n",
      "517     好奇\n",
      "Name: text, dtype: object\n",
      "帮宝适\n",
      "帮宝适--完成抓取\n",
      "好奇\n",
      "好奇--完成抓取\n",
      "save success\n",
      "Wheel  3  OVER\n",
      "Wheel 8 - 10\n",
      "Th- 1 start\titems is :  index\n",
      "518    美素佳儿\n",
      "519      贝亲\n",
      "Name: text, dtype: object\n",
      "美素佳儿\n",
      "美素佳儿--完成抓取\n",
      "贝亲\n",
      "贝亲--完成抓取\n",
      "save success\n",
      "Wheel  4  OVER\n",
      "Wheel 10 - 12\n",
      "Th- 1 start\titems is :  index\n",
      "520     亨氏\n",
      "521    好孩子\n",
      "Name: text, dtype: object\n",
      "亨氏\n",
      "亨氏--完成抓取\n",
      "好孩子\n",
      "好孩子--完成抓取\n",
      "save success\n",
      "Wheel  5  OVER\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import os \n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import threading\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANGE =2\n",
    "THEADING =1\n",
    "\n",
    "def InitChrome():\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    options.add_argument('lang=zh_CN.UTF-8')\n",
    "#    options.add_argument('user-agent=\"Mozilla/5.0 (iPod; U; CPU iPhone OS 2_1 like Mac OS X; ja-jp) AppleWebKit/525.18.1 (KHTML, like Gecko) Version/3.1.1 Mobile/5F137 Safari/525.20\"')\n",
    "    prefs = {\n",
    "        'profile.default_content_setting_values': {\n",
    "        'images': 2\n",
    "        }\n",
    "    }\n",
    "    options.add_argument('--headless') \n",
    "#    options.add_argument('--proxy-server='+ip)\n",
    "    options.add_argument('disable-infobars')\n",
    "    options.add_experimental_option('prefs',prefs)\n",
    "    browser = webdriver.Chrome(chrome_options=options)\n",
    "    return browser\n",
    "\n",
    "def getInformation(item,number):\n",
    "    print('Th-',number,'start',end = '\\t')\n",
    "    print('items is : ',item)\n",
    "    infmoration = []\n",
    "    url = 'https://chaoshi.tmall.com/?targetPage=index'\n",
    "\n",
    "    for i in item:\n",
    "        print(i)\n",
    "        browser = InitChrome()\n",
    "        browser.get(url)\n",
    "        # 清空搜索栏\n",
    "        browser.find_element_by_xpath('//*[@id=\"mq\"]').clear()\n",
    "        # 传入数据\n",
    "        browser.find_element_by_xpath('//*[@id=\"mq\"]').send_keys(i)\n",
    "        time.sleep(random.randint(3,5))\n",
    "        # 点击搜索\n",
    "        browser.find_element_by_xpath('//*[@id=\"mallSearch\"]/form/fieldset/div/button').click()\n",
    "        try:\n",
    "            # 如果有跟多则点击没有就Pass\n",
    "            browser.find_element_by_xpath('//*[@id=\"J_RecommendProp\"]/div/a').click()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            temp = browser.find_element_by_xpath('//*[@id=\"J_RecommendProp\"]/div').text\n",
    "        except:\n",
    "            temp = 'LOST'\n",
    "            print(i+ ' LOST!!!!\\n'+'.*'*40)\n",
    "            pass\n",
    "        infmoration.append(temp)\n",
    "\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print(i,end='--完成抓取\\n')\n",
    "        browser.quit()\n",
    "    infmoration = pd.DataFrame(infmoration,index=item.index,columns=['Brands'])\n",
    "    infmoration.index.name='brandsIndex'\n",
    "    result = pd.concat((item,infmoration),axis =1)\n",
    "    \n",
    "    SaveSQL(result)\n",
    "\n",
    "def SaveSQL(data):\n",
    "    with sqlite3.connect('TmallInformation.db') as con:\n",
    "        data.to_sql(name='brands',con = con ,if_exists='append')\n",
    "    print('save success')\n",
    "\n",
    "def ChromeThread(listRange):\n",
    "    temp = []\n",
    "    for i in range(len(listRange)//THEADING):\n",
    "        print('Wheel',i*THEADING*RANGE,'-',(i+1)*THEADING*RANGE)\n",
    "        temp = listRange[i*THEADING:(i+1)*THEADING]\n",
    "        count = 0\n",
    "        pool = []\n",
    "        for packgae in temp:\n",
    "            count+=1\n",
    "            pool.append(threading.Thread(target = getInformation, args = (packgae, count)))\n",
    "        for j in pool:\n",
    "            j.start()\n",
    "        for j in pool:\n",
    "            j.join()\n",
    "        print('Wheel ' ,i ,' OVER')\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    con = sqlite3.connect('TmallInformation.db')\n",
    "    sql = 'select * from brands'\n",
    "    try:\n",
    "        data= pd.read_sql(con=con,sql = sql,index_col='brandsIndex')\n",
    "    except:\n",
    "        print('表为空')\n",
    "        data = []\n",
    "    if len(data)>0:\n",
    "        ItemsValue = Items[~Items.index.isin( data.index)]\n",
    "    else:\n",
    "        ItemsValue = Items\n",
    "    listRange = []\n",
    "    if len(ItemsValue)>=3:\n",
    "        for i in range(len(ItemsValue)//RANGE):\n",
    "            listRange.append(ItemsValue.iloc[i*RANGE:(i+1)*RANGE])\n",
    "        ChromeThread(listRange)\n",
    "    elif len(ItemsValue)>=1:\n",
    "        getInformation(ItemsValue,0)\n",
    "    else:\n",
    "        print('Over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brands Feature Engering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('TmallInformation.db')\n",
    "sql = 'select * from brands'\n",
    "data= pd.read_sql(con=con,sql = sql,index_col='brandsIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop('Brands',axis = 1).join(data.Brands.str.split('\\n',expand=True).iloc[:,1:].stack().reset_index(level = 1,drop=1).rename('Brands'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_sql(con = con,name='brandsAfFE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
